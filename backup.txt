import cv2
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

def face_match(img_path, data_path): # img_path= location of photo, data_path= location of data.pt 
    # getting embedding matrix of the given img
    
    img_path = cv2.VideoCapture(1)

    while True:
        # Read the frame
        _, img = img_path.read()

        # Convert to grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Detect the faces
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)

        # Draw the rectangle around each face
        for (x, y, w, h) in faces:
            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)
        
        # Display
        cv2.imshow('detect_Face', img)

        # Stop if escape key is pressed
        if cv2.waitKey(1) & 0xFF ==ord('q'):
          break 
            
    # Release the VideoCapture object
    img_path.release()
    

   # img = Image.open(img_path)
    
    face, prob = mtcnn(img, return_prob=True) # returns cropped face and probability
    emb = resnet(face.unsqueeze(0)).detach() # detech is to make required gradient false
    
    saved_data = torch.load('data.pt') # loading data.pt file
    embedding_list = saved_data[0] # getting embedding data
    name_list = saved_data[1] # getting list of names
    dist_list = [] # list of matched distances, minimum distance is used to identify the person
    
    for idx, emb_db in enumerate(embedding_list):
        dist = torch.dist(emb, emb_db).item()
        dist_list.append(dist)
        
    idx_min = dist_list.index(min(dist_list))
    return (name_list[idx_min], min(dist_list))


#result = face_match('Train.jpg' , 'data.pt')
result = face_match(img , 'data.pt')

print('Face matched with: ',result[0], 'With distance: ',result[1])